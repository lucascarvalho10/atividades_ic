{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ANi30Sxb_GFb"
      },
      "source": [
        "# Projeto de IC\n",
        "\n",
        "## Otimização de Hiperparâmetros da Rede Neural"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4DSKCPtd_39q"
      },
      "source": [
        "### Revisão da Proposta"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "frvBmQkjAE-K"
      },
      "source": [
        "As equações de Navier-Stokes descrevem o comportamento de fluidos, incluindo o escoamento plenamente desenvolvido bidimensional em um canal com perfil de velocidade parabólico. Para esse caso específico, em coordenadas cartesianas $(x, y)$, as equações de Navier-Stokes simplificadas podem ser expressas como:\n",
        "\n",
        "\\begin{equation}\n",
        "    \\text{Equação da Conservação da Massa:} \\quad \\frac{\\partial u}{\\partial x} + \\frac{\\partial v}{\\partial y} = 0\n",
        "\\end{equation}\n",
        "    \n",
        "\\begin{equation}\n",
        "    \\text{Equação do Movimento em } x : \\quad \\frac{\\partial u}{\\partial t} + u\\frac{\\partial u}{\\partial x} + v\\frac{\\partial u}{\\partial y} = -\\frac{1}{\\rho}\\frac{\\partial p}{\\partial x} + \\nu\\left(\\frac{\\partial^2 u}{\\partial x^2} + \\frac{\\partial^2 u}{\\partial y^2}\\right)\n",
        "\\end{equation}\n",
        "    \n",
        "\\begin{equation}\n",
        "    \\text{Equação do Movimento em } y: \\quad \\frac{\\partial v}{\\partial t} + u\\frac{\\partial v}{\\partial x} + v\\frac{\\partial v}{\\partial y} = -\\frac{1}{\\rho}\\frac{\\partial p}{\\partial y} + \\nu\\left(\\frac{\\partial^2 v}{\\partial x^2} + \\frac{\\partial^2 v}{\\partial y^2}\\right)\n",
        "\\end{equation}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LKOkkpvH_Nlp"
      },
      "source": [
        "### Preparação do Ambiente"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "7SFl8Jpr_Dcw"
      },
      "outputs": [],
      "source": [
        "# Machine Learning puro\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "# Bibliotecas de apoio\n",
        "import numpy as np\n",
        "import time\n",
        "\n",
        "# Bibliotecas de visualização gráficas\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "#Manipuação de dados\n",
        "import pandas as pd\n",
        "\n",
        "import warnings\n",
        "\n",
        "# Suprimir todos os alertas\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# Alguns sets\n",
        "np.random.seed(1)\n",
        "pd.options.display.float_format = '{:.2f}'.format  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hlinPKa0_bHC"
      },
      "source": [
        "### Tratamento de Dados\n",
        "\n",
        "Aqui, preparam-se os dados para sua importação dentro de um csv, utilizando a biblioteca Pandas. Com isso, é possível metrificar bem adequadamente o impacto dos hiperparâmetros da rede."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "VVwwBVZ6CcWs",
        "outputId": "92a58537-d116-4d7d-d5cf-328f13703b1a"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>run</th>\n",
              "      <th>perda</th>\n",
              "      <th>lr</th>\n",
              "      <th>alpha</th>\n",
              "      <th>numero_pontos</th>\n",
              "      <th>numero_neuronios</th>\n",
              "      <th>numero_camadas</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>nome</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.15</td>\n",
              "      <td>2000</td>\n",
              "      <td>1</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    run  perda   lr  alpha  numero_pontos  numero_neuronios  numero_camadas\n",
              "0  nome   0.01 0.01   0.15           2000                 1              10"
            ]
          },
          "execution_count": 54,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Read the JSON file into a DataFrame\n",
        "df = pd.read_json(\"dados_otimizacao.json\")\n",
        "\n",
        "# Display the DataFrame\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {},
      "outputs": [],
      "source": [
        "# # Adicionando uma linha de cada vez:\n",
        "# new_data = {\n",
        "#     \"run\": \"novo_nome\",\n",
        "#     \"perda\": 0.015,\n",
        "#     \"lr\": 0.02,\n",
        "#     \"alpha\": 0.2,\n",
        "#     \"numero_pontos\": 3000\n",
        "# }\n",
        "\n",
        "# df.loc[len(df)] = new_data\n",
        "# # Salvando como JSON\n",
        "# df.to_json('dados_otimizacao.json', orient='records')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kNu-ndVc_qJV"
      },
      "source": [
        "### Bloco Residual"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "88ItS7HaADnQ"
      },
      "outputs": [],
      "source": [
        "class ResidualBlock(nn.Module):\n",
        "    def __init__(self, in_features, out_features):\n",
        "        super(ResidualBlock, self).__init__()\n",
        "        self.linear1 = nn.Linear(in_features, out_features)\n",
        "        self.linear2 = nn.Linear(out_features, out_features)\n",
        "\n",
        "        # Adicionar camada linear para ajustar dimensões, se necessário\n",
        "        if in_features != out_features:\n",
        "            self.adjust_dimensions = nn.Linear(in_features, out_features)\n",
        "        else:\n",
        "            self.adjust_dimensions = None\n",
        "\n",
        "    def forward(self, x):\n",
        "        residual = x\n",
        "        x = torch.tanh(self.linear1(x))  # Modificado para tangente hiperbólica\n",
        "        x = self.linear2(x)\n",
        "\n",
        "        # Ajustar dimensões da entrada residual, se necessário\n",
        "        if self.adjust_dimensions is not None:\n",
        "            residual = self.adjust_dimensions(residual)\n",
        "\n",
        "        if residual.shape[1] == x.shape[1]:  # Verifica se as dimensões são compatíveis para a conexão de pulo\n",
        "            x += residual  # Conexão de pulo\n",
        "        else:\n",
        "            raise RuntimeError(\"Dimensões incompatíveis para a conexão de pulo.\")\n",
        "        return torch.tanh(x)  # Modificado para tangente hiperbólica"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Classe de Controle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "id": "IJ5_ANWBCs-8"
      },
      "outputs": [],
      "source": [
        "class pinn_ns_class:\n",
        "\n",
        "  def __init__(self, comprimento_x: float, comprimento_y: float, pressao: float,\n",
        "               pontos_no_contorno: int = 1000, pontos_no_dominio: int = 2000, numero_de_neuronios = [3, 20, 20, 20, 2],\n",
        "               pontos_no_contorno_validacao: int = 200, pontos_no_dominio_validacao: int = 300,\n",
        "               alpha: float = 0.2, epocas: int = 10000, learning_rate: float = 0.01,\n",
        "               device = torch.device('cuda' if torch.cuda.is_available () else 'cpu')):\n",
        "\n",
        "      self.comprimento_x = comprimento_x\n",
        "      self.comprimento_y = comprimento_y\n",
        "      self.pressao = pressao\n",
        "      self.alpha = alpha\n",
        "      self.epocas = epocas\n",
        "      self.learning_rate = learning_rate\n",
        "      self.pontos_no_contorno = pontos_no_contorno\n",
        "      self.pontos_no_dominio = pontos_no_dominio\n",
        "      self.numero_de_neuronios = numero_de_neuronios\n",
        "      self.learning_rate = learning_rate\n",
        "      self.pontos_no_contorno_validacao = pontos_no_contorno_validacao\n",
        "      self.pontos_no_dominio_validacao = pontos_no_dominio_validacao\n",
        "\n",
        "      if type(device) == str:\n",
        "        device = torch.device(device)\n",
        "      self.device = device\n",
        "\n",
        "\n",
        "  def gerar_lado(self, pontos_por_lado, comprimento_x, comprimento_y, pressao_total, velocidade = 0):\n",
        "        x = np.random.uniform(size=(pontos_por_lado, 1), low=0, high=comprimento_x)\n",
        "        y = np.random.uniform(size=(pontos_por_lado, 1), low=0, high=comprimento_y)\n",
        "        p = np.random.uniform(size=(pontos_por_lado, 1), low=0, high=pressao_total)\n",
        "        if (velocidade == 0):\n",
        "          u = 0 * np.ones((pontos_por_lado, 1))\n",
        "          v = 0 * np.ones((pontos_por_lado, 1))\n",
        "        else:\n",
        "          u = np.sin(2*np.pi*x)*np.sin(2*np.pi*y)\n",
        "          v = np.sin(np.pi*x)*np.sin(np.pi*y)\n",
        "\n",
        "        return x, y, p, u, v\n",
        "\n",
        "  def gerar_pontos_contorno(self):\n",
        "        pontos_por_lado = self.pontos_no_contorno // 6\n",
        "        x1, y1, p1, u1, v1 = self.gerar_lado(pontos_por_lado, self.comprimento_x, 0, self.pressao)\n",
        "        x2, y2, p2, u2, v2 = self.gerar_lado(pontos_por_lado, 0, self.comprimento_y, self.pressao)\n",
        "        x3, y3, p3, u3, v3 = self.gerar_lado(pontos_por_lado, self.comprimento_x, self.comprimento_y, self.pressao)\n",
        "        x4, y4, p4, u4, v4 = self.gerar_lado(pontos_por_lado, self.comprimento_x, self.comprimento_y, self.pressao)\n",
        "\n",
        "        x_inicial, y_inicial, p_inicial, u_inicial, v_inicial = self.gerar_lado(\n",
        "            2 * pontos_por_lado, self.comprimento_x, self.comprimento_y, 0, 1\n",
        "        )\n",
        "\n",
        "        # Juntar todos os lados\n",
        "        x_todos = np.vstack((x1, x2, x3, x4, x_inicial))\n",
        "        y_todos = np.vstack((y1, y2, y3, y4, y_inicial))\n",
        "        p_todos = np.vstack((p1, p2, p3, p4, p_inicial))\n",
        "        u_todos = np.vstack((u1, u2, u3, u4, u_inicial))\n",
        "        v_todos = np.vstack((v1, v2, v3, v4, v_inicial))\n",
        "\n",
        "        # Criar arrays X e Y\n",
        "        X_contorno = np.hstack((x_todos, y_todos, p_todos))\n",
        "        Y_contorno = np.hstack((u_todos, v_todos))\n",
        "\n",
        "        self.X_contorno = X_contorno\n",
        "        self.Y_contorno = Y_contorno\n",
        "\n",
        "  def gerar_pontos_validacao(self):\n",
        "        pontos_por_lado_validacao = self.pontos_no_contorno_validacao // 6\n",
        "        x1, y1, p1, u1, v1 = self.gerar_lado(pontos_por_lado_validacao, self.comprimento_x, 0, self.pressao)\n",
        "        x2, y2, p2, u2, v2 = self.gerar_lado(pontos_por_lado_validacao, 0, self.comprimento_y, self.pressao)\n",
        "        x3, y3, p3, u3, v3 = self.gerar_lado(pontos_por_lado_validacao, self.comprimento_x, self.comprimento_y, self.pressao)\n",
        "        x4, y4, p4, u4, v4 = self.gerar_lado(pontos_por_lado_validacao, self.comprimento_x, self.comprimento_y, self.pressao)\n",
        "\n",
        "        x_inicial_validacao, y_inicial_validacao, p_inicial_validacao, u_inicial_validacao, v_inicial_validacao = self.gerar_lado(\n",
        "            2 * pontos_por_lado_validacao, self.comprimento_x, self.comprimento_y, 0, 1\n",
        "        )\n",
        "\n",
        "        # Juntar todos os lados em validação\n",
        "        x_todos_validacao = np.vstack((x1, x2, x3, x4, x_inicial_validacao))\n",
        "        y_todos_validacao = np.vstack((y1, y2, y3, y4, y_inicial_validacao))\n",
        "        p_todos_validacao = np.vstack((p1, p2, p3, p4, p_inicial_validacao))\n",
        "        u_todos_validacao = np.vstack((u1, u2, u3, u4, u_inicial_validacao))\n",
        "        v_todos_validacao = np.vstack((v1, v2, v3, v4, v_inicial_validacao))\n",
        "\n",
        "        # Arrays X e Y para validação\n",
        "        X_contorno_validacao = np.hstack((x_todos_validacao, y_todos_validacao, p_todos_validacao))\n",
        "        Y_contorno_validacao = np.hstack((u_todos_validacao, v_todos_validacao))\n",
        "\n",
        "        self.X_contorno_validacao = X_contorno_validacao\n",
        "        self.Y_contorno_validacao = Y_contorno_validacao\n",
        "\n",
        "  def gerar_pontos_equacao(self):\n",
        "    x_dominio = np.random.uniform(size=(self.pontos_no_dominio, 1), low=0, high=self.comprimento_x)\n",
        "    y_dominio = np.random.uniform(size=(self.pontos_no_dominio, 1), low=0, high=self.comprimento_y)\n",
        "    p_dominio = np.random.uniform(size=(self.pontos_no_dominio, 1), low=0, high=self.pressao)\n",
        "\n",
        "    x_dominio_validacao = np.random.uniform(size=(self.pontos_no_dominio_validacao, 1), low=0, high=self.comprimento_x)\n",
        "    y_dominio_validacao = np.random.uniform(size=(self.pontos_no_dominio_validacao, 1), low=0, high=self.comprimento_y)\n",
        "    p_dominio_validacao = np.random.uniform(size=(self.pontos_no_dominio_validacao, 1), low=0, high=self.pressao)\n",
        "\n",
        "    X_equacao = np.hstack((x_dominio, y_dominio, p_dominio))\n",
        "    X_equacao_validacao = np.hstack((x_dominio_validacao, y_dominio_validacao, p_dominio_validacao))\n",
        "\n",
        "    self.X_equacao = torch.tensor(X_equacao, requires_grad=True, dtype=torch.float).to(self.device)\n",
        "    self.X_equacao_validacao = torch.tensor(X_equacao_validacao, requires_grad=True, dtype=torch.float).to(self.device)\n",
        "\n",
        "  def criar_rede_neural(self):\n",
        "      # Criar uma lista de todas as camadas\n",
        "      camadas = []\n",
        "\n",
        "      # Adicionar camadas residuais\n",
        "      for i in range(len(self.numero_de_neuronios)-2):\n",
        "        camadas.append(ResidualBlock(self.numero_de_neuronios[i], self.numero_de_neuronios[i + 1]))\n",
        "\n",
        "      # Última camada sem ativação (pode ser ajustado conforme necessário)\n",
        "      camadas.append(nn.Linear(self.numero_de_neuronios[-2], self.numero_de_neuronios[-1]))\n",
        "\n",
        "      # Criar a rede\n",
        "      self.rna = nn.Sequential(*camadas)\n",
        "\n",
        "  def calcular_gradientes(self, u, v, p, x, y):\n",
        "    # Calcular os gradientes\n",
        "    u_x = torch.autograd.grad(u, x, grad_outputs=torch.ones_like(u), retain_graph=True, create_graph=True, allow_unused=True)[0]\n",
        "    u_y = torch.autograd.grad(u, y, grad_outputs=torch.ones_like(u), retain_graph=True, create_graph=True, allow_unused=True)[0]\n",
        "    u_xx = torch.autograd.grad(u_x, x, grad_outputs=torch.ones_like(u_x), retain_graph=True, create_graph=True, allow_unused=True)[0]\n",
        "    v_x = torch.autograd.grad(v, x, grad_outputs=torch.ones_like(v), retain_graph=True, create_graph=True, allow_unused=True)[0]\n",
        "    v_y = torch.autograd.grad(v, y, grad_outputs=torch.ones_like(v), retain_graph=True, create_graph=True, allow_unused=True)[0]\n",
        "    v_yy = torch.autograd.grad(v_y, y, grad_outputs=torch.ones_like(v_y), retain_graph=True, create_graph=True, allow_unused=True)[0]\n",
        "    p_x = torch.autograd.grad(p, x, grad_outputs=torch.ones_like(p), retain_graph=True, create_graph=True, allow_unused=True)[0]\n",
        "    p_y = torch.autograd.grad(p, y, grad_outputs=torch.ones_like(p), retain_graph=True, create_graph=True, allow_unused=True)[0]\n",
        "\n",
        "    return u_x, u_y, u_xx, v_x, v_y, v_yy, p_x, p_y\n",
        "\n",
        "  def calc_residuo(self):\n",
        "    rho = 997  # densidade do fluido\n",
        "    nu = 0.1   # viscosidade cinemática\n",
        "\n",
        "    x = self.X_equacao[:, 0].reshape(-1, 1)\n",
        "    y = self.X_equacao[:, 1].reshape(-1, 1)\n",
        "    p = self.X_equacao[:, 2].reshape(-1, 1)\n",
        "\n",
        "    x_validacao = self.X_equacao_validacao[:, 0].reshape(-1, 1)\n",
        "    y_validacao = self.X_equacao_validacao[:, 1].reshape(-1, 1)\n",
        "    p_validacao = self.X_equacao_validacao[:, 2].reshape(-1, 1)\n",
        "\n",
        "    V = self.rna(torch.hstack((x, y, p)))\n",
        "    u = V[:, 0].reshape(-1, 1)\n",
        "    v = V[:, 1].reshape(-1, 1)\n",
        "\n",
        "    V_validacao = self.rna(torch.hstack((x_validacao, y_validacao, p_validacao)))\n",
        "    u_validacao = V_validacao[:, 0].reshape(-1, 1)\n",
        "    v_validacao = V_validacao[:, 1].reshape(-1, 1)\n",
        "\n",
        "    u_x, u_y, u_xx, v_x, v_y, v_yy, p_x, p_y = self.calcular_gradientes(u, v, p, x, y)\n",
        "\n",
        "    u_x_validacao, u_y_validacao, u_xx_validacao, v_x_validacao, v_y_validacao, v_yy_validacao, p_x_validacao, p_y_validacao = self.calcular_gradientes(u_validacao, v_validacao, p_validacao, x_validacao, y_validacao)\n",
        "\n",
        "    residual_mass = u_x + v_y  # Conservation of mass\n",
        "    residual_u = u * u_x + v * u_y + (1/rho) - nu * (u_xx + v_yy)\n",
        "    residual_v = u * v_x + v * v_y + (1/rho) - nu * (u_xx + v_yy)\n",
        "\n",
        "    residual_mass_validacao = u_x_validacao + v_y_validacao\n",
        "    residual_u_validacao =  u_validacao * u_x_validacao + v_validacao * u_y_validacao - (1/997) + 1e-6 * (u_xx_validacao + v_yy_validacao)\n",
        "    residual_v_validacao = u_validacao * v_x_validacao + v_validacao * v_y_validacao - (1/997) + 1e-6 * (u_xx_validacao + v_yy_validacao)\n",
        "\n",
        "    self.residual_mass = residual_mass\n",
        "    self.residual_u = residual_u\n",
        "    self.residual_v = residual_v\n",
        "\n",
        "    self.residual_mass_validacao = residual_mass_validacao\n",
        "    self.residual_u_validacao = residual_u_validacao\n",
        "    self.residual_v_validacao = residual_v_validacao\n",
        "\n",
        "    residuo_total = torch.cat((residual_mass, residual_u, residual_v), dim=1)\n",
        "    self.residuo_total = residuo_total\n",
        "\n",
        "    residuo_total_validacao = torch.cat((residual_mass_validacao, residual_u_validacao, residual_v_validacao), dim=1)\n",
        "    self.residuo_total_validacao = residuo_total_validacao\n",
        "\n",
        "\n",
        "    return residuo_total_validacao\n",
        "\n",
        "  def calc_perda_equacao(self):\n",
        "      self.calc_residuo()\n",
        "      residuo = torch.mean(torch.square(self.residuo_total))\n",
        "      residuo_validacao = torch.mean(torch.square(self.residuo_total_validacao))\n",
        "\n",
        "      self.perda_equacao = residuo\n",
        "      self.perda_equacao_validacao = residuo_validacao\n",
        "\n",
        "  def calc_perda(self):\n",
        "      self.calc_perda_contorno()\n",
        "      self.calc_perda_equacao()\n",
        "\n",
        "      perda = (1-self.alpha)*self.perda_contorno + self.alpha*self.perda_equacao\n",
        "      perda_validacao = (1-self.alpha)*self.perda_contorno_validacao + self.alpha*self.perda_equacao_validacao\n",
        "\n",
        "      self.perda = perda\n",
        "      self.perda_validacao = perda_validacao\n",
        "      self.perda_contorno = self.perda_contorno\n",
        "      self.perda_contorno_validacao = self.perda_contorno_validacao\n",
        "      self.perda_equacao = self.perda_equacao\n",
        "      self.perda_equacao_validacao = self.perda_equacao_validacao\n",
        "\n",
        "  def definicao_otimizador(self):\n",
        "      self.gerar_pontos_validacao()\n",
        "      otimizador = torch.optim.Adam(self.rna.parameters(),self.learning_rate)\n",
        "      agendador = torch.optim.lr_scheduler.StepLR(otimizador, step_size=1000, gamma=0.9)\n",
        "\n",
        "      self.X_equacao = torch.tensor(self.X_equacao,requires_grad=True,dtype=torch.float)\n",
        "      self.X_contorno = torch.tensor(self.X_contorno,dtype=torch.float)\n",
        "      self.Y_contorno = torch.tensor(self.Y_contorno,dtype=torch.float)\n",
        "\n",
        "      self.X_equacao = self.X_equacao.to(self.device)\n",
        "      self.X_contorno = self.X_contorno.to(self.device)\n",
        "      self.Y_contorno = self.Y_contorno.to(self.device)\n",
        "      self.rna = self.rna.to(self.device)\n",
        "\n",
        "      self.X_equacao_validacao = torch.tensor(self.X_equacao_validacao,requires_grad=True,dtype=torch.float)\n",
        "      self.X_contorno_validacao = torch.tensor(self.X_contorno_validacao,dtype=torch.float)\n",
        "      self.Y_contorno_validacao = torch.tensor(self.Y_contorno_validacao,dtype=torch.float)\n",
        "\n",
        "      self.X_equacao_validacao = self.X_equacao_validacao.to(self.device)\n",
        "      self.X_contorno_validacao = self.X_contorno_validacao.to(self.device)\n",
        "      self.Y_contorno_validacao = self.Y_contorno_validacao.to(self.device)\n",
        "      self.rna = self.rna.to(self.device)\n",
        "\n",
        "  def calc_perda_contorno(self):\n",
        "    Y_predito = self.rna(self.X_contorno)\n",
        "    Y_predito_validacao = self.rna(self.X_contorno_validacao)\n",
        "\n",
        "    perda_contorno = nn.functional.mse_loss(Y_predito, self.Y_contorno)\n",
        "    perda_contorno_validacao = nn.functional.mse_loss(Y_predito_validacao, self.Y_contorno_validacao)\n",
        "\n",
        "    self.perda_contorno = perda_contorno\n",
        "    self.perda_contorno_validacao = perda_contorno_validacao\n",
        "\n",
        "  def regerar_pontos_equacao(self):\n",
        "    pontos_por_lado = self.pontos_no_dominio // 4\n",
        "\n",
        "    x1, y1, p1, u1, v1 = self.gerar_lado(pontos_por_lado, self.comprimento_x, 0, self.pressao)\n",
        "    x2, y2, p2, u2, v2 = self.gerar_lado(pontos_por_lado, 0, self.comprimento_y, self.pressao)\n",
        "    x3, y3, p3, u3, v3 = self.gerar_lado(pontos_por_lado, self.comprimento_x, self.comprimento_y, self.pressao)\n",
        "    x4, y4, p4, u4, v4 = self.gerar_lado(pontos_por_lado, self.comprimento_x, self.comprimento_y, self.pressao)\n",
        "\n",
        "    # Juntar todos os lados\n",
        "    x_todos = np.vstack((x1, x2, x3, x4))\n",
        "    y_todos = np.vstack((y1, y2, y3, y4))\n",
        "    p_todos = np.vstack((p1, p2, p3, p4))\n",
        "    u_todos = np.vstack((u1, u2, u3, u4))\n",
        "    v_todos = np.vstack((v1, v2, v3, v4))\n",
        "\n",
        "    # Criar arrays X e Y\n",
        "    X_equacao = np.hstack((x_todos, y_todos, p_todos))\n",
        "    Y_equacao = np.hstack((u_todos, v_todos))\n",
        "\n",
        "    # Converter para tensores\n",
        "    X_equacao = torch.tensor(X_equacao, dtype=torch.float).clone().detach().requires_grad_(True).to(self.device)\n",
        "    Y_equacao = torch.tensor(Y_equacao, dtype=torch.float).clone().detach().requires_grad_(True).to(self.device)\n",
        "\n",
        "    self.X_equacao = X_equacao\n",
        "    self.Y_equacao = Y_equacao\n",
        "\n",
        "  def regerar_pontos_contorno(self):\n",
        "    pontos_por_lado = self.pontos_no_contorno // 6\n",
        "    x1, y1, t1, u1, v1 = self.gerar_lado(pontos_por_lado, self.comprimento_x, 0, self.pressao)\n",
        "    x2, y2, t2, u2, v2 = self.gerar_lado(pontos_por_lado, 0, self.comprimento_y, self.pressao)\n",
        "    x3, y3, t3, u3, v3 = self.gerar_lado(pontos_por_lado, self.comprimento_x, self.comprimento_y, self.pressao)\n",
        "    x4, y4, t4, u4, v4 = self.gerar_lado(pontos_por_lado, self.comprimento_x, self.comprimento_y, self.pressao)\n",
        "\n",
        "    x_inicial, y_inicial, t_inicial, u_inicial, v_inicial = self.gerar_lado(\n",
        "        2 * pontos_por_lado, self.comprimento_x, self.comprimento_y, 0, 1\n",
        "    )\n",
        "\n",
        "    # Juntar todos os lados\n",
        "    x_todos = np.vstack((x1, x2, x3, x4, x_inicial))\n",
        "    y_todos = np.vstack((y1, y2, y3, y4, y_inicial))\n",
        "    t_todos = np.vstack((t1, t2, t3, t4, t_inicial))\n",
        "    u_todos = np.vstack((u1, u2, u3, u4, u_inicial))\n",
        "    v_todos = np.vstack((v1, v2, v3, v4, v_inicial))\n",
        "\n",
        "    # Criar arrays X e Y\n",
        "    X_contorno = np.hstack((x_todos, y_todos, t_todos))\n",
        "    Y_contorno = np.hstack((u_todos, v_todos))\n",
        "\n",
        "    # Converter para tensores\n",
        "    # X_contorno = torch.tensor(X_contorno, requires_grad=True, dtype=torch.float).to(self.device)\n",
        "    # Y_contorno = torch.tensor(Y_contorno, requires_grad=True, dtype=torch.float).to(self.device)\n",
        "\n",
        "    X_contorno = torch.tensor(X_contorno, dtype=torch.float).clone().detach().requires_grad_(True).to(self.device)\n",
        "    Y_contorno = torch.tensor(Y_contorno, dtype=torch.float).clone().detach().requires_grad_(True).to(self.device)\n",
        "\n",
        "    self.X_contorno = X_contorno\n",
        "    self.Y_contorno = Y_contorno\n",
        "\n",
        "  def treinamento_da_rede(self):\n",
        "    otimizador = torch.optim.Adam(self.rna.parameters(), lr=self.learning_rate, weight_decay=1e-5)\n",
        "    agendador = torch.optim.lr_scheduler.StepLR(otimizador, step_size=1000, gamma=0.9)\n",
        "\n",
        "    perda_historico = np.zeros(self.epocas)\n",
        "    perda_contorno_historico = np.zeros(self.epocas)\n",
        "    perda_equacao_historico = np.zeros(self.epocas)\n",
        "\n",
        "    perda_historico_validacao = np.zeros(self.epocas)\n",
        "    perda_contorno_historico_validacao = np.zeros(self.epocas)\n",
        "    perda_equacao_historico_validacao = np.zeros(self.epocas)\n",
        "\n",
        "    epocas = np.array(range(self.epocas))\n",
        "\n",
        "    # Colocar rede em modo de treinamento\n",
        "    self.rna.train()\n",
        "\n",
        "    # FAZER ITERAÇÃO\n",
        "    for epoca in epocas:\n",
        "        # Resortear pontos\n",
        "        # self.gerar_pontos_equacao()\n",
        "\n",
        "        # Inicializar gradientes\n",
        "        otimizador.zero_grad()\n",
        "\n",
        "        # Calcular perdas\n",
        "        self.calc_perda()\n",
        "\n",
        "        # Backpropagation\n",
        "        self.perda.backward()\n",
        "\n",
        "        # Passo do otimizador\n",
        "        otimizador.step()\n",
        "        agendador.step()\n",
        "\n",
        "        # Guardar logs\n",
        "        perda_historico[epoca] = self.perda.item()\n",
        "        perda_contorno_historico[epoca] = self.perda_contorno.item()\n",
        "        perda_equacao_historico[epoca] = self.perda_equacao.item()\n",
        "\n",
        "        perda_historico_validacao[epoca] = self.perda_validacao.item()\n",
        "        perda_contorno_historico_validacao[epoca] = self.perda_contorno_validacao.item()\n",
        "        perda_equacao_historico_validacao[epoca] = self.perda_equacao_validacao.item()\n",
        "\n",
        "        # caso queira acompanhar \n",
        "        # if epoca % 500 == 0:\n",
        "        #     print(f'Epoca: {epoca}, Perda: {self.perda.item()} (Contorno: {self.perda_contorno.item()}, Equacao: {self.perda_equacao.item()})')\n",
        "        #     print(f'Perda Validação: {self.perda_validacao.item()} (Contorno Validação: {self.perda_contorno_validacao.item()}, Equacao: {self.perda_equacao_validacao.item()})')\n",
        "\n",
        "        # Ressortear os pontos - evitar overfitting\n",
        "        # self.regerar_pontos_validacao()\n",
        "        self.regerar_pontos_contorno()\n",
        "        self.regerar_pontos_equacao()\n",
        "\n",
        "    self.perda_historico = perda_historico\n",
        "    self.perda_contorno_historico = perda_contorno_historico\n",
        "    self.perda_equacao_historico = perda_equacao_historico\n",
        "\n",
        "    self.perda_historico_validacao = perda_historico_validacao\n",
        "    self.perda_contorno_historico_validacao = perda_contorno_historico_validacao\n",
        "    self.perda_equacao_historico_validacao = perda_equacao_historico_validacao\n",
        "\n",
        "  def calcular_grid(self, nx=101, ny=101,nt=101):\n",
        "    # Definir grid\n",
        "    x = np.linspace(0.,self.comprimento_x,nx)\n",
        "    y = np.linspace(0.,self.comprimento_y,ny)\n",
        "    t = np.linspace(0.,self.pressao,nt)\n",
        "    [t_grid, y_grid, x_grid] = np.meshgrid(t,y,x)\n",
        "\n",
        "    x = torch.tensor(x_grid.flatten()[:,None],requires_grad=True,dtype=torch.float).to(self.device)\n",
        "    y = torch.tensor(y_grid.flatten()[:,None],requires_grad=True,dtype=torch.float).to(self.device)\n",
        "    t = torch.tensor(t_grid.flatten()[:,None],requires_grad=True,dtype=torch.float).to(self.device)\n",
        "\n",
        "    # Avaliar modelor\n",
        "    self.rna.eval()\n",
        "    Y_pred = self.rna(torch.hstack((x,y,t)))\n",
        "    # Formatar resultados em array\n",
        "    u_pred = Y_pred.cpu().detach().numpy()[:,0].reshape(x_grid.shape)\n",
        "    v_pred = Y_pred.cpu().detach().numpy()[:,1].reshape(x_grid.shape)\n",
        "\n",
        "    self.x_grid = x_grid\n",
        "    self.y_grid = y_grid\n",
        "    self.t_grid = t_grid\n",
        "    self.u_pred = u_pred\n",
        "    self.v_pred = v_pred\n",
        "\n",
        "  def plot_historico(self):\n",
        "    # Plotar histórico\n",
        "    epocas = np.array(range(self.epocas))\n",
        "    fig = go.FigureWidget()\n",
        "    fig.add_trace(go.Scatter(x=epocas, y=self.perda_historico, name='Total', line=dict(color='black', width=4)))\n",
        "    fig.add_trace(go.Scatter(x=epocas, y=self.perda_contorno_historico, name='Contorno', line=dict(color='blue', width=2)))\n",
        "    fig.add_trace(go.Scatter(x=epocas, y=self.perda_equacao_historico, name='Equacao', line=dict(color='red', width=2)))\n",
        "    fig.update_yaxes(type=\"log\")\n",
        "    fig.show(renderer=\"colab\")\n",
        "\n",
        "  def plot_comparacao(self):\n",
        "    # Plotar histórico\n",
        "    epocas = np.array(range(self.epocas))\n",
        "    plt.plot(epocas, self.perda_historico, 'b', label=\"Perda do treino\")\n",
        "    plt.plot(epocas, self.perda_historico_validacao, 'r', label=\"Perdas nos pontos de validação\")\n",
        "    plt.xlabel('Épocas')\n",
        "    plt.ylabel('Perdas')\n",
        "    plt.yscale('log')\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "  def plot_resultados(self, epocas=101):\n",
        "    # Calcular valores da função e gerar grids\n",
        "    self.calcular_grid()\n",
        "\n",
        "    ind_t_plot = 50  # Esse é o índice do tempo a ser plotado\n",
        "\n",
        "    # Extrair uma \"fatia\" dos arrays de coordenadas e soluções\n",
        "    x_plot = self.x_grid[:, ind_t_plot, :]\n",
        "    y_plot = self.y_grid[:, ind_t_plot, :]\n",
        "    u_plot = self.u_pred[:, ind_t_plot, :]\n",
        "\n",
        "    # Check dimensions and data types of x_plot, y_plot, and u_plot\n",
        "\n",
        "    # Check if the data is not empty\n",
        "\n",
        "    # Plot the surface\n",
        "    # Check scene settings\n",
        "    fig.update_layout(scene=dict(aspectratio=dict(x=1.5, y=1.5, z=0.5)))\n",
        "\n",
        "    # Show the figure\n",
        "    fig.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Função de Medição de Qualidade"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {},
      "outputs": [],
      "source": [
        "def medicao_qualidade(comprimento_x: int = 1, comprimento_y: int = 1, pressao: int = 1,\n",
        "    pontos_no_contorno: int = 1000, pontos_no_dominio: int = 2000, numero_de_neuronios = [3, 20, 20, 20, 2],\n",
        "    pontos_no_contorno_validacao: int = 200, pontos_no_dominio_validacao: int = 300,\n",
        "    alpha: float = 0.2, epocas: int = 20000, learning_rate: float = 0.01,\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')):\n",
        "\n",
        "    # Criação do Objeto\n",
        "    pinn_ns = pinn_ns_class(comprimento_x, comprimento_y, pressao, pontos_no_contorno, pontos_no_dominio, numero_de_neuronios, pontos_no_contorno_validacao, pontos_no_dominio_validacao, alpha, epocas, learning_rate, device)\n",
        "\n",
        "    # Pontos de contorno e domínio para o treinamento e para a validação\n",
        "    pinn_ns.gerar_pontos_contorno()\n",
        "    pinn_ns.gerar_pontos_equacao()\n",
        "\n",
        "    # Criação da rede\n",
        "    pinn_ns.criar_rede_neural()\n",
        "\n",
        "    # Passando para GPU e otimizando\n",
        "    pinn_ns.definicao_otimizador()\n",
        "\n",
        "    # Realizar as correções nas chamadas dos métodos da classe pinn\n",
        "    pinn_ns.X_contorno = pinn_ns.X_contorno.clone().detach().to(device)\n",
        "    pinn_ns.Y_contorno = pinn_ns.Y_contorno.clone().detach().to(device)\n",
        "    pinn_ns.X_equacao_validacao = pinn_ns.X_equacao_validacao.clone().detach().requires_grad_(True).to(device)\n",
        "    pinn_ns.X_contorno_validacao = pinn_ns.X_contorno_validacao.clone().detach().to(device)\n",
        "    pinn_ns.Y_contorno_validacao = pinn_ns.Y_contorno_validacao.clone().detach().to(device)\n",
        "\n",
        "    # Treinamento\n",
        "    pinn_ns.treinamento_da_rede()\n",
        "\n",
        "\n",
        "    return pinn_ns\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {},
      "outputs": [],
      "source": [
        "# # Function to generate random values for parameters\n",
        "# def generate_random_values():\n",
        "#     lr = 10 ** np.random.uniform(-5, 0)  \n",
        "#     alpha = np.random.uniform(0.1, 0.4)  \n",
        "#     numero_pontos = np.random.randint(1000, 3501)  \n",
        "#     numero_neuronios = np.random.randint(2, 16)  \n",
        "#     numero_camadas = np.random.randint(3, 9)\n",
        "#     return [lr, alpha, numero_pontos, numero_neuronios, numero_camadas]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {},
      "outputs": [],
      "source": [
        "# # Create a dictionary with 5 lists of random parameter values\n",
        "# parameters_dict = {\n",
        "#     f\"experiment_{i+1}\": generate_random_values() for i in range(100)\n",
        "# }\n",
        "\n",
        "# for key, values in parameters_dict.items():\n",
        "#     print(f\"{key}: lr={values[0]}, alpha={values[1]}, numero_pontos={values[2]}, numero_neuronios={values[3]}, numero_camadas={values[4]}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {},
      "outputs": [],
      "source": [
        "# for key, values in parameters_dict.items():\n",
        "#     # Criando o array completo com os valores intermediários\n",
        "#     rede = [3] + [values[3]] * values[4] + [2]\n",
        "#     pinn_ns = medicao_qualidade(1, 1, 1, 1000, values[2], rede, 300, 400, values[1], 700, values[0])\n",
        "    \n",
        "#     new_data = {\n",
        "#         \"run\": key,\n",
        "#         \"perda\": pinn_ns.perda_historico[-1],\n",
        "#         \"lr\": pinn_ns.learning_rate,\n",
        "#         \"alpha\": pinn_ns.alpha,\n",
        "#         \"numero_pontos\": pinn_ns.pontos_no_dominio,\n",
        "#         \"numero_neuronios\": values[3],\n",
        "#         \"numero_camadas\": values[4]\n",
        "#     }\n",
        "\n",
        "#     df.loc[len(df)] = new_data\n",
        "#     # Salvando como JSON\n",
        "#     df.to_json('dados_otimizacao.json', orient='records')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Function to generate initial random values for parameters\n",
        "def generate_initial_values():\n",
        "    lr = 10 ** np.random.uniform(-5, 0)\n",
        "    alpha = np.random.uniform(0.1, 0.4)\n",
        "    numero_pontos = np.random.randint(1000, 3501)\n",
        "    numero_neuronios = np.random.randint(2, 16)\n",
        "    numero_camadas = np.random.randint(3, 9)\n",
        "    return [lr, alpha, numero_pontos, numero_neuronios, numero_camadas]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Initialize parameters\n",
        "initial_values = generate_initial_values()\n",
        "\n",
        "# Create DataFrame to store results\n",
        "columns = [\"run\", \"perda\", \"lr\", \"alpha\", \"numero_pontos\", \"numero_neuronios\", \"numero_camadas\"]\n",
        "df = pd.DataFrame(columns=columns)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Function to run 10 random experiments for one parameter while keeping others fixed\n",
        "def run_experiments(vary_param, fixed_values, trials=10):\n",
        "    param_index = [\"lr\", \"alpha\", \"numero_pontos\", \"numero_neuronios\", \"numero_camadas\"].index(vary_param)\n",
        "    best_result = None\n",
        "\n",
        "    for i in range(trials):\n",
        "        values = fixed_values.copy()\n",
        "\n",
        "        if vary_param == \"lr\":\n",
        "            values[param_index] = 10 ** np.random.uniform(-5, 0)\n",
        "        elif vary_param == \"alpha\":\n",
        "            values[param_index] = np.random.uniform(0.1, 0.4)\n",
        "        elif vary_param == \"numero_pontos\":\n",
        "            values[param_index] = np.random.randint(1000, 3501)\n",
        "        elif vary_param == \"numero_neuronios\":\n",
        "            values[param_index] = np.random.randint(2, 16)\n",
        "        elif vary_param == \"numero_camadas\":\n",
        "            values[param_index] = np.random.randint(3, 9)\n",
        "\n",
        "        rede = [3] + [values[3]] * values[4] + [2]\n",
        "        pinn_ns = medicao_qualidade(1, 1, 1, 1000, values[2], rede, 300, 400, values[1], 10, values[0])\n",
        "        \n",
        "        new_data = {\n",
        "            \"run\": f\"{vary_param}_experiment_{i+1}\",\n",
        "            \"perda\": pinn_ns.perda_historico[-1],\n",
        "            \"lr\": values[0],\n",
        "            \"alpha\": values[1],\n",
        "            \"numero_pontos\": values[2],\n",
        "            \"numero_neuronios\": values[3],\n",
        "            \"numero_camadas\": values[4]\n",
        "        }\n",
        "\n",
        "        df.loc[len(df)] = new_data\n",
        "\n",
        "        if best_result is None or new_data[\"perda\"] < best_result[\"perda\"]:\n",
        "            best_result = new_data\n",
        "    \n",
        "    return best_result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "# Iterate over each parameter to find the optimal values\n",
        "parameters = [\"lr\", \"alpha\", \"numero_pontos\", \"numero_neuronios\", \"numero_camadas\"]\n",
        "\n",
        "for param in parameters:\n",
        "    best_result = run_experiments(param, initial_values)\n",
        "    initial_values[[\"lr\", \"alpha\", \"numero_pontos\", \"numero_neuronios\", \"numero_camadas\"].index(param)] = best_result[param]\n",
        "\n",
        "# Save results to JSON\n",
        "df.to_json('dados_otimizacao.json', orient='records')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {},
      "outputs": [],
      "source": [
        "# pinn_ns = medicao_qualidade(1, 1, 1, 1000, 2000, [3, 100, 100, 100, 100, 100, 2], 300, 400, 0.3, 100, 0.001)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {},
      "outputs": [],
      "source": [
        "# new_data = {\n",
        "#     \"run\": \"lalala\",\n",
        "#     \"perda\": pinn_ns.perda_historico[-1],\n",
        "#     \"lr\": pinn_ns.learning_rate,\n",
        "#     \"alpha\": pinn_ns.alpha,\n",
        "#     \"numero_pontos\": pinn_ns.pontos_no_dominio\n",
        "# }\n",
        "\n",
        "# df.loc[len(df)] = new_data\n",
        "# # Salvando como JSON\n",
        "# df.to_json('dados_otimizacao.json', orient='records')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
