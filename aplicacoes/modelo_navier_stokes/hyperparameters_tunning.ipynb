{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "17yt4kHPQ9bC"
      },
      "source": [
        "## Hyperparameters Tunning with Sweeps"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "uJiWDijbQq4s",
        "outputId": "4da9f05b-f106-493c-9638-369106703234"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting wandb\n",
            "  Downloading wandb-0.16.6-py3-none-any.whl (2.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m20.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: Click!=8.0.0,>=7.1 in /usr/local/lib/python3.10/dist-packages (from wandb) (8.1.7)\n",
            "Collecting GitPython!=3.1.29,>=1.0.0 (from wandb)\n",
            "  Downloading GitPython-3.1.43-py3-none-any.whl (207 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.3/207.3 kB\u001b[0m \u001b[31m14.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (2.31.0)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (5.9.5)\n",
            "Collecting sentry-sdk>=1.0.0 (from wandb)\n",
            "  Downloading sentry_sdk-2.0.1-py2.py3-none-any.whl (266 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m266.8/266.8 kB\u001b[0m \u001b[31m16.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting docker-pycreds>=0.4.0 (from wandb)\n",
            "  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from wandb) (6.0.1)\n",
            "Collecting setproctitle (from wandb)\n",
            "  Downloading setproctitle-1.3.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (30 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from wandb) (67.7.2)\n",
            "Requirement already satisfied: appdirs>=1.4.3 in /usr/local/lib/python3.10/dist-packages (from wandb) (1.4.4)\n",
            "Requirement already satisfied: protobuf!=4.21.0,<5,>=3.19.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (3.20.3)\n",
            "Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\n",
            "Collecting gitdb<5,>=4.0.1 (from GitPython!=3.1.29,>=1.0.0->wandb)\n",
            "  Downloading gitdb-4.0.11-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2024.2.2)\n",
            "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->GitPython!=3.1.29,>=1.0.0->wandb)\n",
            "  Downloading smmap-5.0.1-py3-none-any.whl (24 kB)\n",
            "Installing collected packages: smmap, setproctitle, sentry-sdk, docker-pycreds, gitdb, GitPython, wandb\n",
            "Successfully installed GitPython-3.1.43 docker-pycreds-0.4.0 gitdb-4.0.11 sentry-sdk-2.0.1 setproctitle-1.3.3 smmap-5.0.1 wandb-0.16.6\n"
          ]
        },
        {
          "data": {
            "application/javascript": "\n        window._wandbApiKey = new Promise((resolve, reject) => {\n            function loadScript(url) {\n            return new Promise(function(resolve, reject) {\n                let newScript = document.createElement(\"script\");\n                newScript.onerror = reject;\n                newScript.onload = resolve;\n                document.body.appendChild(newScript);\n                newScript.src = url;\n            });\n            }\n            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n            const iframe = document.createElement('iframe')\n            iframe.style.cssText = \"width:0;height:0;border:none\"\n            document.body.appendChild(iframe)\n            const handshake = new Postmate({\n                container: iframe,\n                url: 'https://wandb.ai/authorize'\n            });\n            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n            handshake.then(function(child) {\n                child.on('authorize', data => {\n                    clearTimeout(timeout)\n                    resolve(data)\n                });\n            });\n            })\n        });\n    ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
            "wandb: Paste an API key from your profile and hit enter, or press ctrl+c to quit:"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " ··········\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.16.6"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20240502_094058-z7arx660</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/ic_pinn/ic_pinn/runs/z7arx660' target=\"_blank\">polar-leaf-43</a></strong> to <a href='https://wandb.ai/ic_pinn/ic_pinn' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/ic_pinn/ic_pinn' target=\"_blank\">https://wandb.ai/ic_pinn/ic_pinn</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/ic_pinn/ic_pinn/runs/z7arx660' target=\"_blank\">https://wandb.ai/ic_pinn/ic_pinn/runs/z7arx660</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Create sweep with ID: d499mod9\n",
            "Sweep URL: https://wandb.ai/ic_pinn/uncategorized/sweeps/d499mod9\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-1-4725d62d6d78>:312: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  self.X_equacao = torch.tensor(self.X_equacao,requires_grad=True,dtype=torch.float)\n",
            "<ipython-input-1-4725d62d6d78>:321: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  self.X_equacao_validacao = torch.tensor(self.X_equacao_validacao,requires_grad=True,dtype=torch.float)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoca: 0, Perda: 0.18373289704322815 (Contorno: 0.22909541428089142, Equacao: 0.0022827566135674715)\n",
            "Perda Validação: 0.1936541348695755 (Contorno Validação: 0.24150629341602325, Equacao: 0.0022454375866800547)\n",
            "Epoca: 500, Perda: 0.02456577867269516 (Contorno: 0.02431635931134224, Equacao: 0.025563448667526245)\n",
            "Perda Validação: 0.030656592920422554 (Contorno Validação: 0.02595580741763115, Equacao: 0.049459729343652725)\n",
            "Epoca: 1000, Perda: 0.022832488641142845 (Contorno: 0.02302011102437973, Equacao: 0.02208198979496956)\n",
            "Perda Validação: 0.02766292169690132 (Contorno Validação: 0.024784427136182785, Equacao: 0.03917689621448517)\n",
            "Epoca: 1500, Perda: 0.023606620728969574 (Contorno: 0.022646741941571236, Equacao: 0.02744612656533718)\n",
            "Perda Validação: 0.029266085475683212 (Contorno Validação: 0.024713853374123573, Equacao: 0.04747501760721207)\n",
            "Epoca: 2000, Perda: 0.0217004232108593 (Contorno: 0.022062454372644424, Equacao: 0.020252292975783348)\n",
            "Perda Validação: 0.027256527915596962 (Contorno Validação: 0.024622980505228043, Equacao: 0.03779071196913719)\n"
          ]
        }
      ],
      "source": [
        "# Import the W&B Python Library and log into W&B\n",
        "!pip install wandb\n",
        "import wandb\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "\n",
        "# Initialize W&B with desired project\n",
        "wandb.init(project=\"ic_pinn\")\n",
        "\n",
        "class ResidualBlock(nn.Module):#\n",
        "    def __init__(self, in_features, out_features):\n",
        "        super(ResidualBlock, self).__init__()\n",
        "        self.linear1 = nn.Linear(in_features, out_features)\n",
        "        self.linear2 = nn.Linear(out_features, out_features)\n",
        "\n",
        "        # Adicionar camada linear para ajustar dimensões, se necessário\n",
        "        if in_features != out_features:\n",
        "            self.adjust_dimensions = nn.Linear(in_features, out_features)\n",
        "        else:\n",
        "            self.adjust_dimensions = None\n",
        "\n",
        "    def forward(self, x):\n",
        "        residual = x\n",
        "        x = torch.tanh(self.linear1(x))  # Modificado para tangente hiperbólica\n",
        "        x = self.linear2(x)\n",
        "\n",
        "        # Ajustar dimensões da entrada residual, se necessário\n",
        "        if self.adjust_dimensions is not None:\n",
        "            residual = self.adjust_dimensions(residual)\n",
        "\n",
        "        if residual.shape[1] == x.shape[1]:  # Verifica se as dimensões são compatíveis para a conexão de pulo\n",
        "            x += residual  # Conexão de pulo\n",
        "        else:\n",
        "            raise RuntimeError(\"Dimensões incompatíveis para a conexão de pulo.\")\n",
        "        return torch.tanh(x)  # Modificado para tangente hiperbólica\n",
        "\n",
        "class pinn:\n",
        "\n",
        "  # Método contrutor\n",
        "  def __init__(self, comprimento_x: int = 1, comprimento_y: int = 1, tempo_final: int = 1,\n",
        "    pontos_no_contorno: int = 1000, pontos_no_dominio: int = 2000, numero_de_neuronios = [3, 20, 20, 20, 2],\n",
        "    pontos_no_contorno_validacao: int = 200, pontos_no_dominio_validacao: int = 300,\n",
        "    alpha: float = 0.2, epocas: int = 20000, learning_rate: float = 0.01,\n",
        "    train: bool = False, verbose: bool = False, max_time = None,\n",
        "    device = torch.device('cuda' if torch.cuda.is_available () else 'cpu')):\n",
        "\n",
        "    self.comprimento_x = comprimento_x\n",
        "    self.comprimento_y = comprimento_y\n",
        "    self.tempo_final = tempo_final\n",
        "    self.alpha = alpha\n",
        "    self.epocas = epocas\n",
        "    self.learning_rate = learning_rate\n",
        "    self.pontos_no_contorno = pontos_no_contorno\n",
        "    self.pontos_no_dominio = pontos_no_dominio\n",
        "    self.numero_de_neuronios = numero_de_neuronios\n",
        "    self.learning_rate = learning_rate\n",
        "    self.pontos_no_contorno_validacao = pontos_no_contorno_validacao\n",
        "    self.pontos_no_dominio_validacao = pontos_no_dominio_validacao\n",
        "\n",
        "    if type(device) == str:\n",
        "        device = torch.device(device)\n",
        "    self.device = device\n",
        "\n",
        "    self.criar_rede_neural()  # Add this line to initialize the neural network\n",
        "\n",
        "    if train:\n",
        "        self.treinamento_da_rede()\n",
        "\n",
        "  def gerar_lado(self, pontos_por_lado, comprimento_x, comprimento_y, tempo_final, velocidade = 0):\n",
        "        x = np.random.uniform(size=(pontos_por_lado, 1), low=0, high=comprimento_x)\n",
        "        y = np.random.uniform(size=(pontos_por_lado, 1), low=0, high=comprimento_y)\n",
        "        t = np.random.uniform(size=(pontos_por_lado, 1), low=0, high=tempo_final)\n",
        "        if (velocidade == 0):\n",
        "          u = 0 * np.ones((pontos_por_lado, 1))\n",
        "          v = 0 * np.ones((pontos_por_lado, 1))\n",
        "        else:\n",
        "          u = np.sin(2*np.pi*x)*np.sin(2*np.pi*y)\n",
        "          v = np.sin(np.pi*x)*np.sin(np.pi*y)\n",
        "\n",
        "        return x, y, t, u, v\n",
        "\n",
        "  def gerar_pontos_contorno(self):\n",
        "        pontos_por_lado = self.pontos_no_contorno // 6\n",
        "        x1, y1, t1, u1, v1 = self.gerar_lado(pontos_por_lado, self.comprimento_x, 0, self.tempo_final)\n",
        "        x2, y2, t2, u2, v2 = self.gerar_lado(pontos_por_lado, 0, self.comprimento_y, self.tempo_final)\n",
        "        x3, y3, t3, u3, v3 = self.gerar_lado(pontos_por_lado, self.comprimento_x, self.comprimento_y, self.tempo_final)\n",
        "        x4, y4, t4, u4, v4 = self.gerar_lado(pontos_por_lado, self.comprimento_x, self.comprimento_y, self.tempo_final)\n",
        "\n",
        "        x_inicial, y_inicial, t_inicial, u_inicial, v_inicial = self.gerar_lado(\n",
        "            2 * pontos_por_lado, self.comprimento_x, self.comprimento_y, 0, 1\n",
        "        )\n",
        "\n",
        "        # Juntar todos os lados\n",
        "        x_todos = np.vstack((x1, x2, x3, x4, x_inicial))\n",
        "        y_todos = np.vstack((y1, y2, y3, y4, y_inicial))\n",
        "        t_todos = np.vstack((t1, t2, t3, t4, t_inicial))\n",
        "        u_todos = np.vstack((u1, u2, u3, u4, u_inicial))\n",
        "        v_todos = np.vstack((v1, v2, v3, v4, v_inicial))\n",
        "\n",
        "        # Criar arrays X e Y\n",
        "        X_contorno = np.hstack((x_todos, y_todos, t_todos))\n",
        "        Y_contorno = np.hstack((u_todos, v_todos))\n",
        "\n",
        "        self.X_contorno = X_contorno\n",
        "        self.Y_contorno = Y_contorno\n",
        "\n",
        "  def gerar_pontos_validacao(self):\n",
        "        pontos_por_lado_validacao = self.pontos_no_contorno_validacao // 6\n",
        "        x1, y1, t1, u1, v1 = self.gerar_lado(pontos_por_lado_validacao, self.comprimento_x, 0, self.tempo_final)\n",
        "        x2, y2, t2, u2, v2 = self.gerar_lado(pontos_por_lado_validacao, 0, self.comprimento_y, self.tempo_final)\n",
        "        x3, y3, t3, u3, v3 = self.gerar_lado(pontos_por_lado_validacao, self.comprimento_x, self.comprimento_y, self.tempo_final)\n",
        "        x4, y4, t4, u4, v4 = self.gerar_lado(pontos_por_lado_validacao, self.comprimento_x, self.comprimento_y, self.tempo_final)\n",
        "\n",
        "        x_inicial_validacao, y_inicial_validacao, t_inicial_validacao, u_inicial_validacao, v_inicial_validacao = self.gerar_lado(\n",
        "            2 * pontos_por_lado_validacao, self.comprimento_x, self.comprimento_y, 0, 1\n",
        "        )\n",
        "\n",
        "        # Juntar todos os lados em validação\n",
        "        x_todos_validacao = np.vstack((x1, x2, x3, x4, x_inicial_validacao))\n",
        "        y_todos_validacao = np.vstack((y1, y2, y3, y4, y_inicial_validacao))\n",
        "        t_todos_validacao = np.vstack((t1, t2, t3, t4, t_inicial_validacao))\n",
        "        u_todos_validacao = np.vstack((u1, u2, u3, u4, u_inicial_validacao))\n",
        "        v_todos_validacao = np.vstack((v1, v2, v3, v4, v_inicial_validacao))\n",
        "\n",
        "        # Arrays X e Y para validação\n",
        "        X_contorno_validacao = np.hstack((x_todos_validacao, y_todos_validacao, t_todos_validacao))\n",
        "        Y_contorno_validacao = np.hstack((u_todos_validacao, v_todos_validacao))\n",
        "\n",
        "        self.X_contorno_validacao = X_contorno_validacao\n",
        "        self.Y_contorno_validacao = Y_contorno_validacao\n",
        "\n",
        "  def gerar_pontos_equacao(self):\n",
        "    x_dominio = np.random.uniform(size=(self.pontos_no_dominio, 1), low=0, high=self.comprimento_x)\n",
        "    y_dominio = np.random.uniform(size=(self.pontos_no_dominio, 1), low=0, high=self.comprimento_y)\n",
        "    t_dominio = np.random.uniform(size=(self.pontos_no_dominio, 1), low=0, high=self.tempo_final)\n",
        "\n",
        "    x_dominio_validacao = np.random.uniform(size=(self.pontos_no_dominio_validacao, 1), low=0, high=self.comprimento_x)\n",
        "    y_dominio_validacao = np.random.uniform(size=(self.pontos_no_dominio_validacao, 1), low=0, high=self.comprimento_y)\n",
        "    t_dominio_validacao = np.random.uniform(size=(self.pontos_no_dominio_validacao, 1), low=0, high=self.tempo_final)\n",
        "\n",
        "    X_equacao = np.hstack((x_dominio, y_dominio, t_dominio))\n",
        "    X_equacao_validacao = np.hstack((x_dominio_validacao, y_dominio_validacao, t_dominio_validacao))\n",
        "\n",
        "    self.X_equacao = torch.tensor(X_equacao, requires_grad=True, dtype=torch.float).to(self.device)\n",
        "    self.X_equacao_validacao = torch.tensor(X_equacao_validacao, requires_grad=True, dtype=torch.float).to(self.device)\n",
        "\n",
        "  def criar_rede_neural(self):\n",
        "        # Criar uma lista de todas as camadas\n",
        "        camadas = []\n",
        "\n",
        "        # Adicionar camadas residuais\n",
        "        for i in range(len(self.numero_de_neuronios)-2):\n",
        "            camadas.append(ResidualBlock(self.numero_de_neuronios[i], self.numero_de_neuronios[i + 1]))\n",
        "\n",
        "            # adicionar dropout\n",
        "            # camadas.append(nn.Dropout(p=0.5))\n",
        "\n",
        "        # Última camada sem ativação (pode ser ajustado conforme necessário)\n",
        "        camadas.append(nn.Linear(self.numero_de_neuronios[-2], self.numero_de_neuronios[-1]))\n",
        "\n",
        "        # Criar a rede\n",
        "        self.rna = nn.Sequential(*camadas)\n",
        "\n",
        "  def calc_perda_contorno(self):\n",
        "    Y_predito = self.rna(self.X_contorno)\n",
        "    Y_predito_validacao = self.rna(self.X_contorno_validacao)\n",
        "\n",
        "    perda_contorno = nn.functional.mse_loss(Y_predito, self.Y_contorno)\n",
        "    perda_contorno_validacao = nn.functional.mse_loss(Y_predito_validacao, self.Y_contorno_validacao)\n",
        "\n",
        "    self.perda_contorno = perda_contorno\n",
        "    self.perda_contorno_validacao = perda_contorno_validacao\n",
        "\n",
        "  def regerar_pontos_contorno(self):\n",
        "    pontos_por_lado = self.pontos_no_contorno // 6\n",
        "    x1, y1, t1, u1, v1 = self.gerar_lado(pontos_por_lado, self.comprimento_x, 0, self.tempo_final)\n",
        "    x2, y2, t2, u2, v2 = self.gerar_lado(pontos_por_lado, 0, self.comprimento_y, self.tempo_final)\n",
        "    x3, y3, t3, u3, v3 = self.gerar_lado(pontos_por_lado, self.comprimento_x, self.comprimento_y, self.tempo_final)\n",
        "    x4, y4, t4, u4, v4 = self.gerar_lado(pontos_por_lado, self.comprimento_x, self.comprimento_y, self.tempo_final)\n",
        "\n",
        "    x_inicial, y_inicial, t_inicial, u_inicial, v_inicial = self.gerar_lado(\n",
        "        2 * pontos_por_lado, self.comprimento_x, self.comprimento_y, 0, 1\n",
        "    )\n",
        "\n",
        "    # Juntar todos os lados\n",
        "    x_todos = np.vstack((x1, x2, x3, x4, x_inicial))\n",
        "    y_todos = np.vstack((y1, y2, y3, y4, y_inicial))\n",
        "    t_todos = np.vstack((t1, t2, t3, t4, t_inicial))\n",
        "    u_todos = np.vstack((u1, u2, u3, u4, u_inicial))\n",
        "    v_todos = np.vstack((v1, v2, v3, v4, v_inicial))\n",
        "\n",
        "    # Criar arrays X e Y\n",
        "    X_contorno = np.hstack((x_todos, y_todos, t_todos))\n",
        "    Y_contorno = np.hstack((u_todos, v_todos))\n",
        "\n",
        "    # Converter para tensores\n",
        "    # X_contorno = torch.tensor(X_contorno, requires_grad=True, dtype=torch.float).to(self.device)\n",
        "    # Y_contorno = torch.tensor(Y_contorno, requires_grad=True, dtype=torch.float).to(self.device)\n",
        "\n",
        "    X_contorno = torch.tensor(X_contorno, dtype=torch.float).clone().detach().requires_grad_(True).to(self.device)\n",
        "    Y_contorno = torch.tensor(Y_contorno, dtype=torch.float).clone().detach().requires_grad_(True).to(self.device)\n",
        "\n",
        "    self.X_contorno = X_contorno\n",
        "    self.Y_contorno = Y_contorno\n",
        "\n",
        "  def regerar_pontos_equacao(self):\n",
        "    pontos_por_lado = self.pontos_no_dominio // 4\n",
        "\n",
        "    x1, y1, t1, u1, v1 = self.gerar_lado(pontos_por_lado, self.comprimento_x, 0, self.tempo_final)\n",
        "    x2, y2, t2, u2, v2 = self.gerar_lado(pontos_por_lado, 0, self.comprimento_y, self.tempo_final)\n",
        "    x3, y3, t3, u3, v3 = self.gerar_lado(pontos_por_lado, self.comprimento_x, self.comprimento_y, self.tempo_final)\n",
        "    x4, y4, t4, u4, v4 = self.gerar_lado(pontos_por_lado, self.comprimento_x, self.comprimento_y, self.tempo_final)\n",
        "\n",
        "    # Juntar todos os lados\n",
        "    x_todos = np.vstack((x1, x2, x3, x4))\n",
        "    y_todos = np.vstack((y1, y2, y3, y4))\n",
        "    t_todos = np.vstack((t1, t2, t3, t4))\n",
        "    u_todos = np.vstack((u1, u2, u3, u4))\n",
        "    v_todos = np.vstack((v1, v2, v3, v4))\n",
        "\n",
        "    # Criar arrays X e Y\n",
        "    X_equacao = np.hstack((x_todos, y_todos, t_todos))\n",
        "    Y_equacao = np.hstack((u_todos, v_todos))\n",
        "\n",
        "    # Converter para tensores\n",
        "    X_equacao = torch.tensor(X_equacao, dtype=torch.float).clone().detach().requires_grad_(True).to(self.device)\n",
        "    Y_equacao = torch.tensor(Y_equacao, dtype=torch.float).clone().detach().requires_grad_(True).to(self.device)\n",
        "\n",
        "    self.X_equacao = X_equacao\n",
        "    self.Y_equacao = Y_equacao\n",
        "\n",
        "\n",
        "  def calcular_gradientes(self, u, v, x, y, t):\n",
        "        u_x = torch.autograd.grad(u, x, grad_outputs=torch.ones_like(u), retain_graph=True, create_graph=True)[0]\n",
        "        u_xx = torch.autograd.grad(u_x, x, grad_outputs=torch.ones_like(u), retain_graph=True, create_graph=True)[0]\n",
        "        u_y = torch.autograd.grad(u, y, grad_outputs=torch.ones_like(u), retain_graph=True, create_graph=True)[0]\n",
        "        u_yy = torch.autograd.grad(u_y, y, grad_outputs=torch.ones_like(u), retain_graph=True, create_graph=True)[0]\n",
        "\n",
        "        v_x = torch.autograd.grad(v, x, grad_outputs=torch.ones_like(u), retain_graph=True, create_graph=True)[0]\n",
        "        v_xx = torch.autograd.grad(v_x, x, grad_outputs=torch.ones_like(u), retain_graph=True, create_graph=True)[0]\n",
        "        v_y = torch.autograd.grad(v, y, grad_outputs=torch.ones_like(u), retain_graph=True, create_graph=True)[0]\n",
        "        v_yy = torch.autograd.grad(v_y, y, grad_outputs=torch.ones_like(u), retain_graph=True, create_graph=True)[0]\n",
        "\n",
        "        u_t = torch.autograd.grad(u, t, grad_outputs=torch.ones_like(u), retain_graph=True, create_graph=True)[0]\n",
        "        v_t = torch.autograd.grad(v, t, grad_outputs=torch.ones_like(u), retain_graph=True, create_graph=True)[0]\n",
        "\n",
        "        return u_x, u_xx, u_y, u_yy, v_x, v_xx, v_y, v_yy, u_t, v_t\n",
        "\n",
        "  def calc_residuo(self):\n",
        "        x = self.X_equacao[:, 0].reshape(-1, 1)\n",
        "        y = self.X_equacao[:, 1].reshape(-1, 1)\n",
        "        t = self.X_equacao[:, 2].reshape(-1, 1)\n",
        "\n",
        "        x_validacao = self.X_equacao_validacao[:, 0].reshape(-1, 1)\n",
        "        y_validacao = self.X_equacao_validacao[:, 1].reshape(-1, 1)\n",
        "        t_validacao = self.X_equacao_validacao[:, 2].reshape(-1, 1)\n",
        "\n",
        "        V = self.rna(torch.hstack((x, y, t)))\n",
        "        u = V[:, 0].reshape(-1, 1)\n",
        "        v = V[:, 1].reshape(-1, 1)\n",
        "\n",
        "        V_validacao = self.rna(torch.hstack((x_validacao, y_validacao, t_validacao)))\n",
        "        u_validacao = V_validacao[:, 0].reshape(-1, 1)\n",
        "        v_validacao = V_validacao[:, 1].reshape(-1, 1)\n",
        "\n",
        "        u_x, u_xx, u_y, u_yy, v_x, v_xx, v_y, v_yy, u_t, v_t = self.calcular_gradientes(u, v, x, y, t)\n",
        "        u_x_validacao, u_xx_validacao, u_y_validacao, u_yy_validacao, v_x_validacao, v_xx_validacao, v_y_validacao, v_yy_validacao, u_t_validacao, v_t_validacao = self.calcular_gradientes(u_validacao, v_validacao, x_validacao, y_validacao, t_validacao)\n",
        "\n",
        "        residual_u = (u_t + u * u_x + v * u_y - 0.01/np.pi * (u_xx + u_yy))\n",
        "        residual_v = (v_t + u * v_x + v * v_y - 0.01/np.pi * (v_xx + v_yy))\n",
        "\n",
        "        residual_u_validacao = (u_t_validacao + u_validacao * u_x_validacao + v_validacao * u_y_validacao - 0.01/np.pi * (u_xx_validacao + u_yy_validacao))\n",
        "        residual_v_validacao = (v_t_validacao + u_validacao * v_x_validacao + v_validacao * v_y_validacao - 0.01/np.pi * (v_xx_validacao + v_yy_validacao))\n",
        "\n",
        "        residuo_total = torch.cat((residual_u, residual_v), dim=1)\n",
        "        self.residuo_total = residuo_total\n",
        "\n",
        "        residuo_total_validacao = torch.cat((residual_u_validacao, residual_v_validacao), dim=1)\n",
        "        self.residuo_total_validacao = residuo_total_validacao\n",
        "        return residuo_total_validacao\n",
        "\n",
        "  def calc_perda_equacao(self):\n",
        "    self.calc_residuo()\n",
        "    residuo = torch.mean(torch.square(self.residuo_total))\n",
        "    residuo_validacao = torch.mean(torch.square(self.residuo_total_validacao))\n",
        "\n",
        "    self.perda_equacao = residuo\n",
        "    self.perda_equacao_validacao = residuo_validacao\n",
        "\n",
        "  def calc_perda(self):\n",
        "\n",
        "    self.calc_perda_contorno()\n",
        "    self.calc_perda_equacao()\n",
        "\n",
        "    perda = (1-self.alpha)*self.perda_contorno + self.alpha*self.perda_equacao\n",
        "    perda_validacao = (1-self.alpha)*self.perda_contorno_validacao + self.alpha*self.perda_equacao_validacao\n",
        "\n",
        "    self.perda = perda\n",
        "    self.perda_validacao = perda_validacao\n",
        "    self.perda_contorno = self.perda_contorno\n",
        "    self.perda_contorno_validacao = self.perda_contorno_validacao\n",
        "    self.perda_equacao = self.perda_equacao\n",
        "    self.perda_equacao_validacao = self.perda_equacao_validacao\n",
        "\n",
        "  def definicao_otimizador(self):\n",
        "      self.gerar_pontos_validacao()\n",
        "      otimizador = torch.optim.Adam(self.rna.parameters(),self.learning_rate)\n",
        "      agendador = torch.optim.lr_scheduler.StepLR(otimizador, step_size=1000, gamma=0.9)\n",
        "\n",
        "      self.X_equacao = torch.tensor(self.X_equacao,requires_grad=True,dtype=torch.float)\n",
        "      self.X_contorno = torch.tensor(self.X_contorno,dtype=torch.float)\n",
        "      self.Y_contorno = torch.tensor(self.Y_contorno,dtype=torch.float)\n",
        "\n",
        "      self.X_equacao = self.X_equacao.to(self.device)\n",
        "      self.X_contorno = self.X_contorno.to(self.device)\n",
        "      self.Y_contorno = self.Y_contorno.to(self.device)\n",
        "      self.rna = self.rna.to(self.device)\n",
        "\n",
        "      self.X_equacao_validacao = torch.tensor(self.X_equacao_validacao,requires_grad=True,dtype=torch.float)\n",
        "      self.X_contorno_validacao = torch.tensor(self.X_contorno_validacao,dtype=torch.float)\n",
        "      self.Y_contorno_validacao = torch.tensor(self.Y_contorno_validacao,dtype=torch.float)\n",
        "\n",
        "      self.X_equacao_validacao = self.X_equacao_validacao.to(self.device)\n",
        "      self.X_contorno_validacao = self.X_contorno_validacao.to(self.device)\n",
        "      self.Y_contorno_validacao = self.Y_contorno_validacao.to(self.device)\n",
        "      self.rna = self.rna.to(self.device)\n",
        "\n",
        "  def treinamento_da_rede(self):\n",
        "    otimizador = torch.optim.Adam(self.rna.parameters(), lr=self.learning_rate, weight_decay=1e-5)\n",
        "    agendador = torch.optim.lr_scheduler.StepLR(otimizador, step_size=1000, gamma=0.9)\n",
        "\n",
        "    perda_historico = np.zeros(self.epocas)\n",
        "    perda_contorno_historico = np.zeros(self.epocas)\n",
        "    perda_equacao_historico = np.zeros(self.epocas)\n",
        "\n",
        "    perda_historico_validacao = np.zeros(self.epocas)\n",
        "    perda_contorno_historico_validacao = np.zeros(self.epocas)\n",
        "    perda_equacao_historico_validacao = np.zeros(self.epocas)\n",
        "\n",
        "    epocas = np.array(range(self.epocas))\n",
        "\n",
        "    self.gerar_pontos_contorno()\n",
        "    self.gerar_pontos_equacao()\n",
        "\n",
        "    # Passando para GPU e otimizando\n",
        "    self.definicao_otimizador()\n",
        "\n",
        "    # Realizar as correções nas chamadas dos métodos da classe pinn\n",
        "    self.X_contorno = self.X_contorno.clone().detach().to(torch.device('cuda' if torch.cuda.is_available() else 'cpu'))\n",
        "    self.Y_contorno = self.Y_contorno.clone().detach().to(torch.device('cuda' if torch.cuda.is_available() else 'cpu'))\n",
        "    self.X_equacao_validacao = self.X_equacao_validacao.clone().detach().requires_grad_(True).to(torch.device('cuda' if torch.cuda.is_available() else 'cpu'))\n",
        "    self.X_contorno_validacao = self.X_contorno_validacao.clone().detach().to(torch.device('cuda' if torch.cuda.is_available() else 'cpu'))\n",
        "    self.Y_contorno_validacao = self.Y_contorno_validacao.clone().detach().to(torch.device('cuda' if torch.cuda.is_available() else 'cpu'))\n",
        "\n",
        "    # Colocar rede em modo de treinamento\n",
        "    self.rna.train()\n",
        "\n",
        "    # FAZER ITERAÇÃO\n",
        "    for epoca in epocas:\n",
        "        # Resortear pontos\n",
        "        # self.gerar_pontos_equacao()\n",
        "\n",
        "        # Inicializar gradientes\n",
        "        otimizador.zero_grad()\n",
        "\n",
        "        # Calcular perdas\n",
        "        self.calc_perda()\n",
        "\n",
        "        # Backpropagation\n",
        "        self.perda.backward()\n",
        "\n",
        "        # Passo do otimizador\n",
        "        otimizador.step()\n",
        "        agendador.step()\n",
        "\n",
        "        # Guardar logs\n",
        "        perda_historico[epoca] = self.perda.item()\n",
        "        perda_contorno_historico[epoca] = self.perda_contorno.item()\n",
        "        perda_equacao_historico[epoca] = self.perda_equacao.item()\n",
        "\n",
        "        perda_historico_validacao[epoca] = self.perda_validacao.item()\n",
        "        perda_contorno_historico_validacao[epoca] = self.perda_contorno_validacao.item()\n",
        "        perda_equacao_historico_validacao[epoca] = self.perda_equacao_validacao.item()\n",
        "\n",
        "        for name, param in self.rna.named_parameters():\n",
        "            wandb.log({f'Gradient/{name}': param.grad.norm().item()}, step=epoca)\n",
        "\n",
        "        if epoca % 500 == 0:\n",
        "            print(f'Epoca: {epoca}, Perda: {self.perda.item()} (Contorno: {self.perda_contorno.item()}, Equacao: {self.perda_equacao.item()})')\n",
        "            print(f'Perda Validação: {self.perda_validacao.item()} (Contorno Validação: {self.perda_contorno_validacao.item()}, Equacao: {self.perda_equacao_validacao.item()})')\n",
        "\n",
        "        # Ressortear os pontos - evitar overfitting\n",
        "        # self.regerar_pontos_validacao()\n",
        "        self.regerar_pontos_contorno()\n",
        "        self.regerar_pontos_equacao()\n",
        "        wandb.log({'epoch': epoca, 'loss': self.perda.item()})\n",
        "\n",
        "    self.perda_historico = perda_historico\n",
        "    self.perda_contorno_historico = perda_contorno_historico\n",
        "    self.perda_equacao_historico = perda_equacao_historico\n",
        "\n",
        "    self.perda_historico_validacao = perda_historico_validacao\n",
        "    self.perda_contorno_historico_validacao = perda_contorno_historico_validacao\n",
        "    self.perda_equacao_historico_validacao = perda_equacao_historico_validacao\n",
        "\n",
        "sweep_config = {\n",
        "    'method': 'random'\n",
        "}\n",
        "\n",
        "metric = {\n",
        "    'name': 'loss',\n",
        "    'goal': 'minimize'\n",
        "}\n",
        "\n",
        "sweep_config['metric'] = metric\n",
        "\n",
        "parameters_dict = {\n",
        "    'comprimento_y': {\n",
        "        'distribution': 'uniform',\n",
        "        'max': 1.5,\n",
        "        'min': 0.5,\n",
        "    },\n",
        "    'comprimento_x': {\n",
        "        'distribution': 'uniform',\n",
        "        'max': 1.5,\n",
        "        'min': 0.5,\n",
        "    },\n",
        "    'pressao': {\n",
        "        'distribution': 'uniform',\n",
        "        'max': 1.5,\n",
        "        'min': 0.5,\n",
        "    },\n",
        "    'epocas': {'value': 10000},\n",
        "    'learning_rate': {\n",
        "        'distribution': 'uniform',\n",
        "        'max': 0.1,\n",
        "        'min': 0.0\n",
        "    },\n",
        "    'alpha': {\n",
        "        'distribution': 'uniform',\n",
        "        'max': 0.3,\n",
        "        'min': 0.05\n",
        "    },\n",
        "}\n",
        "\n",
        "sweep_config['parameters'] = parameters_dict\n",
        "\n",
        "# Create the sweep\n",
        "sweep_id = wandb.sweep(sweep_config)\n",
        "\n",
        "# Start the agent\n",
        "wandb.agent(sweep_id, pinn().treinamento_da_rede(), count=5)\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
